{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c26d403-6587-45a2-8c0b-a9839f943e10",
   "metadata": {},
   "source": [
    "# Brownspot Disease Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e7fe9-0cd9-46bf-a685-69e900b58ad9",
   "metadata": {},
   "source": [
    "Preprocessing is the general term for all transformation done to the data before feeding it into the model. The various steps include centering, normalization, shift, rotation, shear and so on. There are few occasions when we need to preprocess data. Among these include:\n",
    "\n",
    "   - Cleaning up the data\n",
    "   - Augmenting the data\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee94511-d8a4-4817-89b6-9d4f68dda42b",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa1a66-e657-4609-b419-4bdb79c3e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a811c-f91c-4961-abb2-f8852632ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee11100-9368-4efe-976c-5c2112cb28fc",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79e5e1-5ade-4d87-bf33-5b7b5e055e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:\\\\Users\\\\Keith\\\\Desktop\\\\Brownspot Detector\\\\3. Data Preprocessing\\\\train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6cf4f-3176-4bf7-800e-550af3ad5b19",
   "metadata": {},
   "source": [
    "# Cleaning Transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1ebed-8f44-4f97-9901-2b525c34ede1",
   "metadata": {},
   "source": [
    "**1. Rescaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f75f3d-3bf8-4ce0-86d7-98022dd89be8",
   "metadata": {},
   "source": [
    "Rescaling is an operation that moves the data from one numerical range to another by simple division using a predefined constant.\n",
    "\n",
    "In Deep neural nteworks, we usually want to restrict the input to the range of 0 to 1, due to possible overflow, optimization and stability issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a004946-eee7-4e48-b38a-0fc5df587a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9c939-365b-4fce-a31e-e0760a19bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 4000\n",
    "img_width = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab45e3-f23e-41a0-87d0-9bd6930fbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_rescaled = ImageDataGenerator(rescale=1. / 255.)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695fd69-b52d-4bdc-9718-5eeb3019eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_rescaled = datagen_rescaled.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9925d80-351f-44bd-bf1f-26aa1d5523f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_rescaled = next(gen_rescaled)\n",
    "compare_images(sample_default[0], sample_rescaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024de62-2769-46a2-906c-23cc7c77c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_default[0][:2, :2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41096291-1a72-4431-bd37-eefa0a211646",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rescaled[0][:2, :2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1d1b5-8aa9-403b-927f-51f3d64ee989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f125a24b-2af3-4718-a3d7-c1cb6a22d7e0",
   "metadata": {},
   "source": [
    "**2. Grayscaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602b98a-b1d9-4560-8ad7-4ed13e0878a6",
   "metadata": {},
   "source": [
    "Grayscaling turns color RGB image into images with only shades of gray representing colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e8d2d-99e7-4833-be4a-c9d2f6abd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808dbd7-1818-4259-bd06-2ac5562741e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_grayscaled = datagen_default.flow_from_directory(train_path, \n",
    "                                                     target_size=(img_height, img_width), \n",
    "                                                     batch_size=1, \n",
    "                                                     shuffle=False, \n",
    "                                                     class_mode=None, \n",
    "                                                     color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d86c9-4a56-4df2-a554-5bb7908fbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_grayscaled = next(gen_grayscaled)\n",
    "compare_images(sample_default[0], sample_grayscaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3056e2-d302-4f19-86e6-429419be7686",
   "metadata": {},
   "source": [
    "**3. Samplewise Centering**  **- across features inside one sample**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085cd6d0-c52d-4c57-b103-47e95193660b",
   "metadata": {},
   "source": [
    "The raw data value in an image are from 0 to 255. One sample is a 3d array of numbers from  0 to 255. We might want to normalize the dataset such that the mean value of each data sample is equal to 0.\n",
    "\n",
    "Therefore, we calculate the mean value across one whole sample and subtract it from each number in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc515d-8432-48cf-991b-62f972860138",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_samplewise_mean = ImageDataGenerator(samplewise_center=True)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f33dc4-df9b-4512-856c-2932cda12ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_samplewise_mean = datagen_samplewise_mean.flow_from_directory(train_path, \n",
    "                                                                  target_size=(img_height, img_width), \n",
    "                                                                  batch_size=1, \n",
    "                                                                  shuffle=False,  \n",
    "                                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f123e8-d3c7-4861-951c-95865c04872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_samplewise_mean = next(gen_samplewise_mean)\n",
    "compare_images(sample_default[0], sample_samplewise_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1a3fd-7998-4617-af8b-9c925cb457a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac94bf0-21d6-4ad5-9c8b-baf5dc53b21f",
   "metadata": {},
   "source": [
    "**4. Samplewise std normalization**  **-across features inside one sample**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e1d9a-2a9f-4cfe-86e2-3c24680bc57e",
   "metadata": {},
   "source": [
    "This is a similar idea as samplewise centering, but instead of setting the mean value to 0, here we set the standard deviation value to 1. \n",
    "\n",
    "Std normalization is controlled by the keras option **samplewise_std_normalization**. It is a common practice to use these two samplewise normalization options simultaneously.\n",
    "\n",
    "This helps in improving the optimization stability by reducing the influence of exploding gradients problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c735abf-309c-4a52-a2ad-17a38704fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_samplewise_std = ImageDataGenerator(samplewise_std_normalization=True)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf592b-11e8-4be8-a021-5941f06c77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_samplewise_std = datagen_samplewise_std.flow_from_directory(train_path, \n",
    "                                                                target_size=(img_height, img_width), \n",
    "                                                                batch_size=1, \n",
    "                                                                shuffle=False, \n",
    "                                                                class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e997ea-a4bd-4a25-adaf-0e35487e51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_samplewise_std = next(gen_samplewise_std)\n",
    "compare_images(sample_default[0], sample_samplewise_std[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0b0cb-8241-48ef-9ad4-31ec478ae985",
   "metadata": {},
   "source": [
    "**5. Featurewise centering** **- across samples in dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e56329-ba7b-471d-bc92-0355a8d3523d",
   "metadata": {},
   "source": [
    "Here each number in the image array is treated as a feature. Then each image is represented by a vector of features.\n",
    "Because there are plenty of such vectors in the dataset, therefore treat them as coming from some unknown distribution.\n",
    "\n",
    "The distribution will be multivariate and the dimension of space will be equal to the number of features which is **width x height x 3**.\n",
    "\n",
    "Though we don't know the real distribution of the data, we normalize it by subtracting the mean value of the distribution.\n",
    "\n",
    "Here the mean value is the vector of the same dimension as space i.e., it is an image itself. (***we average across the dataset and not across one sample***)\n",
    "\n",
    "The whole dataset is read into memory by setting the batch size to the size of the dataset.\n",
    "\n",
    "The man image across the dataset is calculated.\n",
    "\n",
    "Finally the mean is subtracted from the test image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7ea84-2a32-4032-b0ef-90fc22a3d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47d971-ae2e-4d94-a184-05d585809fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_dataset = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  shuffle=False, \n",
    "                                                  batch_size=gen_dataset.n, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee7ae8-7f03-4b97-a56d-86d17c803cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = next(gen_dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2855c3-b153-4215-8117-d7bc732dac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = dataset.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa93fb1-24dd-4cf8-8b7e-58269445fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32d5e4-64f6-465c-9ba7-23d0e18cae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_featurewise_mean = sample_default - mean_image\n",
    "compare_images(sample_default[0], sample_featurewise_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3087c-ee41-4f58-a857-f62e6e6a50ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f7cbafb-a26e-4a69-a45f-bc4bdfab38cd",
   "metadata": {},
   "source": [
    "**6. Featurewise std normalization** **-across samples in dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b591baf-0715-4044-8551-1faa8f943f38",
   "metadata": {},
   "source": [
    "The idea behind featurewise standard deviation normalization is exactly the same as featurewise centering. The difference is that here we divid by the sample standard deviation instead of subtracting the mean value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3df80-bb22-4c81-ae61-071c7cbf7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b8ceb-1528-479a-9244-e2e0a84d28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dataset = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_dataset = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  shuffle=False, \n",
    "                                                  batch_size=gen_dataset.n, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195aad0-20e8-4910-833d-ba3d1534ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = next(gen_dataset)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf65ef-6eab-43b4-95e6-460399d1d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_image = dataset.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3c059-cac5-47c0-a0e4-12de1fbc6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d09879-68ed-43dd-8db3-b407b5dd30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_featurewise_std = sample_default / std_image\n",
    "compare_images(sample_default[0], sample_featurewise_std[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91fcbf-f8e7-4c5b-8a15-b510373ed2e7",
   "metadata": {},
   "source": [
    "# Augmentation Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb9f16-e6d4-4d1f-aec5-02518b06c9b2",
   "metadata": {},
   "source": [
    "These are data-dependent transformations which explicitly use the graphical nature of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125930d-7ad6-485c-be6b-e1fb5de215c6",
   "metadata": {},
   "source": [
    "**1. Rotation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf127fe-5456-41ca-8964-e8f4a7aac046",
   "metadata": {},
   "source": [
    "This transformation rotates the image in a certain direction (clockwise or anticlockwise).\n",
    "The parameter that allows the rotations is called **rotation_range**. it specifies the range of rotations in degrees from which the random angle will be chosen uniformly to do a rotation.\n",
    "\n",
    "Note that some of image regions are cropped out and some of the regions of the new image will need to be filled. Thus the filling mode can be set up by the **fill_mode** parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46ac80-1ce8-4db1-a9b9-42065cd73fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_rotated = ImageDataGenerator(rotation_range=45, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f610f6-d454-4562-a6f8-e423d3d386b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_rotated = datagen_rotated.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7235f1-ece3-4c37-85d2-a36bd695aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_rotated = next(gen_rotated)\n",
    "compare_images(sample_default[0], sample_rotated[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b506a-df8b-4c7a-9f2b-826d35c9076d",
   "metadata": {},
   "source": [
    "**2. Horizontal shift**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac6489-1dac-42f4-a871-fb450b6ff059",
   "metadata": {},
   "source": [
    "This transformation shifts the image to a certain direction along the horizontal axis(left or right).\n",
    "\n",
    "The size of the shift can be determined using the **width_shift_range** parameter and is measured as a fraction of the the total width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1559f56-8576-431a-9c76-e2846d83b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_hshifted = ImageDataGenerator(width_shift_range=0.4, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c048a8-4069-4945-b3ee-f20c5dd3daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_hshifted = datagen_hshifted.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0231048-a9a8-4765-9372-579a84134154",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_hshifted = next(gen_hshifted)\n",
    "compare_images(sample_default[0], sample_hshifted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff8c5c2-2c87-4947-a48a-ebb14cf53f43",
   "metadata": {},
   "source": [
    "**3. Vertical shift**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951455f-b874-4efc-b2fe-5d47d05ef518",
   "metadata": {},
   "source": [
    "This transformation shifts the image to a certain direction along the vertical axis(down or up).\n",
    "\n",
    "The size of the shift can be determined using the **height_shif** generator and is measured as a fraction of the the total height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6ac10-bdee-408b-b36e-5ee45a531608",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_vshifted = ImageDataGenerator(height_shift_range=0.4, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adcfe1-d420-4a9b-806d-899b0e63fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_vshifted = datagen_vshifted.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fa32a-56a4-4b6d-9c54-426e74d1b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_vshifted = next(gen_vshifted)\n",
    "compare_images(sample_default[0], sample_vshifted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb0f45-cdc3-4b69-ad81-d9b7c5e0e042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bdc302d-ee9a-4894-9c94-ad2ce53fb944",
   "metadata": {},
   "source": [
    "**4. Shearing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930fc3a-5ec8-4e10-a632-912c26ae7a4b",
   "metadata": {},
   "source": [
    "Shear mapping or shearing displaces each point in the vertical direction by an amount proportional to its distance from an edge of the image.\n",
    "\n",
    "**NB:** The direction doesn't have to be vertical and can be arbitrary.\n",
    "\n",
    "The parameter that controls the displacement is called **shear_range** and corresponds to the deviation angle (in radians) between a horizontal line in the original picture and the image of this line in the transformed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0aecc-fd7d-4b97-83a4-af5bf5886ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_sheared = ImageDataGenerator(shear_range=0.75, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6278869-d65d-4864-9e62-6628e9707675",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_sheared = datagen_sheared.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f761a-e1d0-4e53-a848-9368b6f65b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_sheared = next(gen_sheared)\n",
    "compare_images(sample_default[0], sample_sheared[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb6164-6695-4bfb-8c11-ac304e3632c3",
   "metadata": {},
   "source": [
    "**5. Zoom**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12acfc58-ea98-4c6e-9185-9b709559e82e",
   "metadata": {},
   "source": [
    "This transformation zooms the initial image in or out. The **zoom_range** parameter controls the zooming factor.\n",
    "\n",
    "For example, **zoom_range** is equal to 0.5 means that implies that the zooming factor will be chosen from the range [0.5, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddf2f1-057b-4521-8ef3-565758324ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_zoomed = ImageDataGenerator(zoom_range=0.5, fill_mode=\"constant\")\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523f74a-2752-4838-ab13-9f2c5339776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_zoomed = datagen_zoomed.flow_from_directory(train_path, \n",
    "                                                target_size=(img_height, img_width), \n",
    "                                                batch_size=1, \n",
    "                                                shuffle=False, \n",
    "                                                class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820d48d-494d-4981-9442-fa4b4d85135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_zoomed = next(gen_zoomed)\n",
    "compare_images(sample_default[0], sample_zoomed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146dd5ae-d34a-4432-98a5-427c204d720b",
   "metadata": {},
   "source": [
    "**6. Horizontal Flip**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d033-775b-456a-bb14-ca3e74f648e6",
   "metadata": {},
   "source": [
    "This flips the image with respect to the vertical axis. One can either turn it on or off using the horizontal_flip parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0e065-dd75-43fb-b51e-f4322d774bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_hflipped = ImageDataGenerator(horizontal_flip=True)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d55cf-2ecc-40c8-b04a-df060d4743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_hflipped = datagen_hflipped.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4632d3-f49c-4ef0-be8f-959f9c714779",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_hflipped = next(gen_hflipped)\n",
    "compare_images(sample_default[0], sample_hflipped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451651e-e730-4954-9a21-85a3bfc254c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0de772-a370-46e1-b791-0dcdf86bdcd7",
   "metadata": {},
   "source": [
    "**7. Vertical Flip**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c801d17-181f-4ebc-993b-307923bf448c",
   "metadata": {},
   "source": [
    "This flips the image with regard to the horizontal axis. The **vertical_flip** Boolean parameter controls the presence of this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b88669-2538-442e-b4d1-51d57deed577",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_vflipped = ImageDataGenerator(vertical_flip=True)\n",
    "datagen_default = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a659a4-3302-4e0b-b198-9a3d86498f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_default = datagen_default.flow_from_directory(train_path, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=1, \n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode=None)\n",
    "gen_vflipped = datagen_vflipped.flow_from_directory(train_path, \n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=1, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac9e65-aac1-42b1-800a-11913403d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "sample_default = next(gen_default)\n",
    "sample_vflipped = next(gen_vflipped)\n",
    "compare_images(sample_default[0], sample_vflipped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8d3d7-d710-4e77-9577-5c194022c6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ded26685-0249-4952-8680-bb6b928a4beb",
   "metadata": {},
   "source": [
    "# Combination of the Techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c670028e-ffb9-46d5-a53b-da4968990e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d37cb-7373-4e65-9574-c4104434824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=45, \n",
    "                             width_shift_range=0.2, \n",
    "                             height_shift_range=0.2, \n",
    "                             shear_range=0.2, \n",
    "                             zoom_range=0.3, \n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True, \n",
    "                             fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc7e3a-ae0e-46c9-a02e-9a185ed95705",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    img = load_img(os.path.join(train_pos_path, \"Firehydrant2.jpg\"))\n",
    "except:\n",
    "    img = load_img(os.path.join(valid_pos_path, \"Firehydrant2.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2c4f9-c829-40c3-aac2-6db27ad1042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de75fb-b3a9-4bee-a4fd-4c0d6ec5245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b7ae1-a4a9-476b-bad8-b9b3c77bf8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_augmentations = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f9a46-eb5b-4cbc-bb85-11e149c23d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_path, \"augmentation_preview\")\n",
    "if os.path.exists(save_dir):\n",
    "    shutil.rmtree(save_dir)\n",
    "os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d89bd6-1322-4f75-a4fd-c5a2c3c6fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))    \n",
    "i = 0\n",
    "\n",
    "for batch in datagen.flow(img, \n",
    "                          batch_size=1, \n",
    "                          seed=21, \n",
    "                          save_to_dir=save_dir, \n",
    "                          save_prefix=\"hydrant\", \n",
    "                          save_format=\"jpeg\"):\n",
    "    \n",
    "    plt.subplot(2, int(np.ceil(n_augmentations * 1. / 2)), i + 1)\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    i += 1\n",
    "    if i >= n_augmentations:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
