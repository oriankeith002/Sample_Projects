{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \n",
    "test_path = \n",
    "save_path = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_id'] = df['Label'].factorize()[0]\n",
    "\n",
    "#view the first 10 entries of label_id\n",
    "df['label_id'][0:10]\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_df = df[['Label','label_id']].drop_duplicates().sort_values('label_id')\n",
    "\n",
    "label_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = dict(label_id_df.values)\n",
    "id_to_label = dict(label_id_df[['label_id','Label']].values)\n",
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Label').label_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Label').label_id.count().plot.bar(ylim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chichewa = ['i', 'ine', 'wanga', 'inenso', 'ife', 'athu',\n",
    "            'athu', 'tokha', 'inu', 'ndinu','iwe ukhoza',\n",
    "            'wako','wekha','nokha','iye','wake','iyemwini',\n",
    "            'icho','ndi','zake','lokha','iwo','awo','iwowo',\n",
    "            'chiyani','amene', 'uyu', 'uyo', 'awa', \"ndili\", \n",
    "            'ndi', 'ali','anali','khalani','akhala','kukhala',\n",
    "            ' Khalani nawo','wakhala','anali','chitani',\n",
    "            'amachita','kuchita', 'a', 'an', 'pulogalamu ya',\n",
    "            'ndi', 'koma', 'ngati', 'kapena', 'chifukwa',\n",
    "            'monga', 'mpaka', 'pamene', 'wa', 'pa ',' by',\n",
    "            'chifukwa' 'ndi','pafupi','kutsutsana','pakati',\n",
    "            'kupyola','nthawi', 'nthawi','kale','pambuyo',\n",
    "            'pamwamba', 'pansipa', 'kuti', 'kuchokera',\n",
    "            'mmwamba', 'pansi', 'mu', 'kunja', 'kuyatsa', \n",
    "            'kuchoka', 'kutha', 'kachiwiri', 'kupitilira',\n",
    "            'kenako',' kamodzi','apa','apo','liti','pati',\n",
    "            'bwanji','onse','aliyense','onse','aliyense', \n",
    "            'ochepa', 'zambiri', 'ambiri', 'ena', 'otero', \n",
    "            'ayi', 'kapena', 'osati', 'okha', 'eni', 'omwewo', \n",
    "            'kotero',' kuposa','nawonso',' kwambiri','angathe',\n",
    "            'ndidzatero','basi','musatero', 'musachite',\n",
    "            ' muyenera', 'muyenera kukhala','tsopano', 'sali', \n",
    "            'sindinathe','​​sanachite','satero','analibe', \n",
    "            'sanatero','sanachite','sindinatero','ayi','si', \n",
    "            'ma', 'sizingatheke','mwina','sayenera', 'osowa',\n",
    "            'osafunikira', 'shan' , 'nenani', 'sayenera', 'sanali', \n",
    "            'anapambana', 'sangachite', 'sanakonde', 'sangatero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf = True,\n",
    "                        min_df = 5, \n",
    "                        norm = 'l2',\n",
    "                        encoding = 'latin-1',\n",
    "                        ngram_range = (1,2),\n",
    "                        stop_words = chichewa)\n",
    "\n",
    "features = tfidf.fit_transform(df.Text).toarray()\n",
    "\n",
    "labels = df.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(label_to_id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "N = 4 # We are going to look for the top 4  categories.\n",
    "\n",
    "\n",
    "#for each Label, find words that are highly correleated to it.\n",
    "\n",
    "for Label, label_id in sorted(label_to_id.items()):\n",
    "    #Do chi2 analyses of all items in this category.\n",
    "    features_chi2 = chi2(features, labels == label_id)\n",
    "    #sorts the indices of features_chi2[0] - the chi-squared stats of each feature\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    #converts indices to feature names (in increasing order of chi squared stat values)\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    #list of single word features (in increasing order of chi squared stat values)\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    #list of two-word features (in increasing order of chi-squared stat values)\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    \n",
    "    print(\"# '{}':\".format(Label))\n",
    "    print(\" .Most correlated unigrams: \\n    .{}\".format('\\n       .'.join(unigrams[-N:]))) #print 4 unigrams with highest chi squared stat\n",
    "    print(\" . Most correleated bigrams:\\n     .{}\".format('\\n      .'.join(bigrams[-N:]))) # print 4 bigrams with highest chi squared stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is computationally very expensive use carefully crashes kernels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Sampling a subset of our dataset because t-sne is computationally expensive \n",
    "SAMPLE_SIZE = int(len(features) * 0.1)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#randomly select 10% of the samples\n",
    "indices = np.random.choice(range(len(features)), size = SAMPLE_SIZE, replace = False)\n",
    "\n",
    "#Array of all projected features of 10% of chosen samples.\n",
    "projected_features = TSNE(n_components = 2, random_state = 0).fit_transform(features[indices])\n",
    "\n",
    "project_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_id = 0 # select a label_id\n",
    "projected_features[(labels[indices]== my_id).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['pink', 'green', 'midnightblue', 'orange', 'darkgrey']\n",
    "\n",
    "#Find points belonging to each Label and plot them \n",
    "\n",
    "for label, label_id in sorted(label_to_id.items()):\n",
    "    points = projected_features[(labels[indices] == category_id).values]\n",
    "    plt.scatter(points[:,0], point[:,1], s = 30, c = colors[category_id], label = Label)\n",
    "plt.title(\"tf-idf feature vector for each article, projected on 2 dimensions\",fontdict = dict(fontsize = 15))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators = 200, max_depth = 100, random_state = 0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state = 30),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 5\n",
    "\n",
    "#Create a dataframe tat will store athe results for all 5 trials\n",
    "cv_df = pd.DataFrame(index = range(CV * len(models)))\n",
    "entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    #create 3 models with different 20% test sets and store their results\n",
    "    accuraciies = cross_val_score(model, features, labels, scoring = 'accuracy', cv = CV)\n",
    "    \n",
    "    #Append all 5 accuracies into the entries list\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(entries, columns = ['model_name', 'fold_idx','accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x = 'model_name', y = 'accuracy', data = cv_df)\n",
    "sns.stripplot(x = 'model_name', y = 'accuracy', data = cv_df, size = 8, jitter = True, edgecolor = 'gray', linewidth = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupb('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = LogisticRegression(random_stat = 0)\n",
    "\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train,y_test , indices_train , indices_test = train_test_split(features,\n",
    "                                                                                  labels, \n",
    "                                                                                  df.index,\n",
    "                                                                                  test_size =0.2, \n",
    "                                                                                  random_state = 42)\n",
    "\n",
    "#train the algorithm\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#make predictions\n",
    "y_pred_proba  model.predict_proba(X_test)\n",
    "y_pred  = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat, annot = True, fmt = 'd',\n",
    "            xticklabels = label_id_df.Label.values, \n",
    "            yticklabels = label_id_df.Label.values)\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for predicted in label_id_df.label_id:\n",
    "    for actual in label_id_df.label_id:\n",
    "        if predicted != actual and con_mat[actual, predicted] >= 2:\n",
    "            print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_label[actual], id_to_label[predicted], conf_mat[actual,predicted]))\n",
    "            display(df.loc[indices_test[(y_test == actual) & (y_pred == predicted)]]['Text'])\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "N = 5\n",
    "for Label, label_id in sorted(label_to_id.items()):\n",
    "  indices = np.argsort(model.coef_[label_id])   # This time using the model co-eficients / weights\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "  bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "  print(\"# '{}':\".format(Category))\n",
    "  print(\"  . Top unigrams:\\n       . {}\".format('\\n       . '.join(unigrams)))\n",
    "  print(\"  . Top bigrams:\\n       . {}\".format('\\n       . '.join(bigrams)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [#YOUR SAMPLE TEXTS HERE]\n",
    "text_features = tfidf.transform(texts)\n",
    "predictions = model.predict(text_features)\n",
    "for text, predicted in zip(texts, predictions):\n",
    "  print('\"{}\"'.format(text))\n",
    "  print(\"  - Predicted as: '{}'\".format(id_to_category[predicted]))\n",
    "  print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = tfidf.transform(test_df.Text.tolist())\n",
    "\n",
    "Y_pred = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_name = []\n",
    "for lab_id in Y_pred:\n",
    "    Y_pred_name.append(id_to_label[lab_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame([\n",
    "    \"ID\":test_df[\"IDS\"]\n",
    "    \"Label\":Y_pred_name\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
